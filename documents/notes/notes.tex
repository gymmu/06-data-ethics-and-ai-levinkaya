\documentclass{article}

\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{csquotes}

\usepackage[
    backend=biber,
    style=apa,
    sortlocale=de_DE,
    natbib=true,
    url=false,
    doi=false,
    sortcites=true,
    sorting=nyt,
    isbn=false,
    hyperref=true,
    backref=false,
    giveninits=false,
    eprint=false]{biblatex}
\addbibresource{../references/bibliography.bib}

\title{Notizen zum Projekt Data Ethics}
\author{Levin Kaya}
\date{\today}

\begin{document}
\maketitle

\abstract{
    Dieses Dokument ist eine Sammlung von Notizen zu dem Projekt. Die Struktur innerhalb des
    Projektes ist gleich ausgelegt wie in der Hauptarbeit, somit kann hier einfach geschrieben
    werden, und die Teile die man verwenden möchte, kann man direkt in die Hauptdatei ziehen.
}

\tableofcontents

\section{Einleitung}
Zu Beginn dieser Arbeit werde ich auf die allgemeine Frage, woher die KI ihre Informationen bezieht eingehen und um welche spezifischen Datenquellen es sich dabei handelt. 
\subsection{Datenfütterung}
Das sogenannten Large Language Modell (LLM) wird von einer gigantischen Menge an Informationen aus dem Internet gefüttert, darunter milliarden von Büchern, Artikeln, Websites und Posts.
\subsection{Filterung der Quellen} 
Die Qualität der Informationen variiert dabei stark, von seriösen Quellen wie beispielsweise wissenschaftlicher Lieratur bis hin zu völlig falschen Angaben aus Foren oder Social Media. Aus diesem Grund werden einige unerwünschte Inhalte, wie ''Wie baut man eine Bombe'' herausgefiltert und nicht beantwortet. Während dieses Prozesses werden zudem doppelte Quellen, sogennante Duplikate gelöscht. Die gesammelten Daten werden bereinigt und in ein Format gebracht, das das Modell verarbeiten kann.
\subsection{Das Trainieren der KI} 
Genau auf diese Art und Weise wird also Chat GBT trainiert, sie ist nämlich ein Modell, bei welchem Einträge gemacht werden, so lange, bis sie präzise werden und ziemlich wahrscheinlich der Wahrheit entsprechen. Kleine Abschnitte werden durch viele Schichten dieses Modelles geschickt. Wenn also immer wieder Einträge gemacht werden, kann es so trainiert werden, dass die Antworten, die die KI generiert aus vielen unterschiedlichen basieren und somit immer effizienter und genauer werden. Nutzer:innen können mit einem ChatBot kommunizieren und eine Eingabe erstellen wie z.B. ''Wie verbessere ich meinen Schlaf?'' Nach dem Begriff durchsucht der Bot das Netzwerk und kombiniert dies mit der Eingabe. Er such den Begriff ''Schlaf'' und versucht diesen mit der Eingabe in einen Kontext zu bringen. Seine Rückgabe ist demnach eine Berechnung der Wörter, die am ehesten darauf folgen. Im gewählten Beispiel ''Wie verbessere ich meinen Schlaf'' antwortet die KI vermutlich mit ''regelmässige Schlafzeiten'' als vorhersehbarste Lösung. Die Qualität der Vorhersagen, welche die KI als Lösung zurückgibt werden dadurch berechnet,wie weit die Vorhersagen vom tatsächlichen nächsten Wort entfernt sind.
Die Gewichte, die Parameter genannt werden durch Optimierungsalgorhytmen angepasst. Das Ziel des Trainierens ist es, über viele Schritte hinweg die Fehler der künstlichen Intelligenz zu reduzieren. Die Gewichtung der Parameter sind ausschlaggebend für das Modell.

\subsection{Das Validieren und Testen}
Durchs Validieren kann man beim KI- Modell sicherstellen, dass es sich bei den Rückgaben nichz ausschliesslich um auswenig gelernte Inhalte handelt, sondern dass sie das Muster versteht. Das Ziel ist es, dass es möglichst gut in der Lage ist, auf ähnliche Fragen, auf die es nicht direkt trainiert wurde zu antworten. Die Ersteller hinter dem Ganzen wollen ein Sprachmodell erstellen, welches leistungsfähig und facettenreich ist. Selbst nachdem das Modell vollständig ist wird es auf einem sogenannten seperratem ''Testdatensatz'' geprüft.

\section{Fragestellung}
Wie kann man sicherstellen, dass die Antworten, die von einer Künstlichen Intelligenz generiert werden, auf vertrauenswürdigen und nachvollziehbaren Quellen basieren?



\section{Informationsquelle der KI}
Wie bereits in meiner Einleitung grob beschrieben und in meiner Fragestellung erläutert, werde ich nun explizieter auf die Informationsquellen der KI und der mit sich bringenden Problematiken eingehen. Das Trainieren der KI habe ich bereits erklärt und ebenfalls das es auf die Korrektheit der Quellen keine Garantie gibt



problematiken: Raub, oben erklärt kinder falschinformationen weitergeben, ethische werte führt zu brainwashed
daten 2021
moralische fragen meit unsicher
nur eine wahrscheinlichkeit




github copilot
raub
unkorrekte Informationsquelle
keine weitere kontrolle
lehrpersonen könnens nicht benutzen
lwhrpersonen können falsche infos weitergeben (sek,primar)
riesen problematik
bei generierung des textes keine genauigkeit
mensch auch keine garantie aufb korrektheit
kritisch hinterfragen, auch was lehrpersonen sagen
zerstört die vielfalt
ki lernt abbildung der daten
subsection möglich
ki wird trainiert aufgrund der daten
anpassen der parameter wichtig
fazit
grösser/kleiner machen
stefani dokument, welches er geschickt hat.
farben, kursiv unerwünschte
\printbibliography


\end{document}
